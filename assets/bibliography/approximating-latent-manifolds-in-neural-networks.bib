@article{fefferman2013testing,
  title   = {Testing the Manifold Hypothesis},
  author  = {Fefferman, Charles and Mitter, Sanjoy and Narayanan, Hariharan},
  journal = {arXiv preprint arXiv:1310.0425},
  year    = {2013},
  url     = {https://arxiv.org/abs/1310.0425},
  doi     = {10.48550/arXiv.1310.0425}
}

@InProceedings{wirth_conditional_2024,
  title = 	 { Conditional Gradients for the Approximately Vanishing Ideal },
  author =       {Wirth, Elias S. and Pokutta, Sebastian},
  booktitle = 	 {Proceedings of The 25th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {2191--2209},
  year = 	 {2022},
  editor = 	 {Camps-Valls, Gustau and Ruiz, Francisco J. R. and Valera, Isabel},
  volume = 	 {151},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {28--30 Mar},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v151/wirth22a/wirth22a.pdf},
  url = 	 {https://proceedings.mlr.press/v151/wirth22a.html},
  abstract = 	 { The vanishing ideal of a set of points X is the set of polynomials that evaluate to 0 over all points x in X and admits an efficient representation by a finite set of polynomials called generators. To accommodate the noise in the data set, we introduce the Conditional Gradients Approximately Vanishing Ideal algorithm (CGAVI) for the construction of the set of generators of the approximately vanishing ideal. The constructed set of generators captures polynomial structures in data and gives rise to a feature map that can, for example, be used in combination with a linear classifier for supervised learning. In CGAVI, we construct the set of generators by solving specific instances of (constrained) convex optimization problems with the Pairwise Frank-Wolfe algorithm (PFW). Among other things, the constructed generators inherit the LASSO generalization bound and not only vanish on the training but also on out-sample data. Moreover, CGAVI admits a compact representation of the approximately vanishing ideal by constructing few generators with sparse coefficient vectors. }
}

@InProceedings{wirth_approximate_2023,
title={Approximate Vanishing Ideal Computations at Scale},
author={Elias Samuel Wirth and Hiroshi Kera and Sebastian Pokutta},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=3ZPESALKXO}
}



@inproceedings{livni_vanishing_2013,
	address = {Atlanta, Georgia, USA},
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {Vanishing Component Analysis},
	volume = {28},
	url = {https://proceedings.mlr.press/v28/livni13.html},
	abstract = {The vanishing ideal of a set of n points S, is the set of all polynomials that attain the value of zero on all the points in S. Such ideals can be compactly represented using a small set of polynomials known as generators of the ideal. Here we describe and analyze an efficient procedure that constructs a set of generators of a vanishing ideal. Our procedure is numerically stable, and can be used to find approximately vanishing polynomials. The resulting polynomials capture nonlinear structure in data, and can for example be used within supervised learning. Empirical comparison with kernel methods show that our method constructs more compact classifiers with comparable accuracy.},
	booktitle = {Proceedings of the 30th International Conference on Machine Learning},
	publisher = {PMLR},
	author = {Livni, Roi and Lehavi, David and Schein, Sagi and Nachliely, Hila and Shalev-Shwartz, Shai and Globerson, Amir},
	editor = {Dasgupta, Sanjoy and McAllester, David},
	month = jun,
	year = {2013},
	note = {Issue: 1},
	pages = {597--605},
}
