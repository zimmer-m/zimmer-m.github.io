@article{fefferman2013testing,
  title   = {Testing the Manifold Hypothesis},
  author  = {Fefferman, Charles and Mitter, Sanjoy and Narayanan, Hariharan},
  journal = {arXiv preprint arXiv:1310.0425},
  year    = {2013},
  url     = {https://arxiv.org/abs/1310.0425},
  doi     = {10.48550/arXiv.1310.0425}
}

@InProceedings{wirth_conditional_2024,
  title = 	 { Conditional Gradients for the Approximately Vanishing Ideal },
  author =       {Wirth, Elias S. and Pokutta, Sebastian},
  booktitle = 	 {Proceedings of The 25th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {2191--2209},
  year = 	 {2022},
  editor = 	 {Camps-Valls, Gustau and Ruiz, Francisco J. R. and Valera, Isabel},
  volume = 	 {151},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {28--30 Mar},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v151/wirth22a/wirth22a.pdf},
  url = 	 {https://proceedings.mlr.press/v151/wirth22a.html},
  abstract = 	 { The vanishing ideal of a set of points X is the set of polynomials that evaluate to 0 over all points x in X and admits an efficient representation by a finite set of polynomials called generators. To accommodate the noise in the data set, we introduce the Conditional Gradients Approximately Vanishing Ideal algorithm (CGAVI) for the construction of the set of generators of the approximately vanishing ideal. The constructed set of generators captures polynomial structures in data and gives rise to a feature map that can, for example, be used in combination with a linear classifier for supervised learning. In CGAVI, we construct the set of generators by solving specific instances of (constrained) convex optimization problems with the Pairwise Frank-Wolfe algorithm (PFW). Among other things, the constructed generators inherit the LASSO generalization bound and not only vanish on the training but also on out-sample data. Moreover, CGAVI admits a compact representation of the approximately vanishing ideal by constructing few generators with sparse coefficient vectors. }
}

@InProceedings{wirth_approximate_2023,
title={Approximate Vanishing Ideal Computations at Scale},
author={Elias Samuel Wirth and Hiroshi Kera and Sebastian Pokutta},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=3ZPESALKXO}
}

@inproceedings{livni_vanishing_2013,
	address = {Atlanta, Georgia, USA},
	series = {Proceedings of Machine Learning Research},
	title = {Vanishing Component Analysis},
	volume = {28},
	url = {https://proceedings.mlr.press/v28/livni13.html},
	abstract = {The vanishing ideal of a set of n points S, is the set of all polynomials that attain the value of zero on all the points in S. Such ideals can be compactly represented using a small set of polynomials known as generators of the ideal. Here we describe and analyze an efficient procedure that constructs a set of generators of a vanishing ideal. Our procedure is numerically stable, and can be used to find approximately vanishing polynomials. The resulting polynomials capture nonlinear structure in data, and can for example be used within supervised learning. Empirical comparison with kernel methods show that our method constructs more compact classifiers with comparable accuracy.},
	booktitle = {Proceedings of the 30th International Conference on Machine Learning},
	publisher = {PMLR},
	author = {Livni, Roi and Lehavi, David and Schein, Sagi and Nachliely, Hila and Shalev-Shwartz, Shai and Globerson, Amir},
	editor = {Dasgupta, Sanjoy and McAllester, David},
	month = jun,
	year = {2013},
	note = {Issue: 1},
	pages = {597--605},
}

@article{brahma_why_2016,
  title      = {Why Deep Learning Works: A Manifold Disentanglement Perspective},
  volume     = {27},
  copyright  = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  issn       = {2162-237X, 2162-2388},
  shorttitle = {Why {Deep} {Learning} {Works}},
  url        = {http://ieeexplore.ieee.org/document/7348689/},
  doi        = {10.1109/TNNLS.2015.2496947},
  number     = {10},
  urldate    = {2024-04-23},
  journal    = {IEEE Transactions on Neural Networks and Learning Systems},
  author     = {Brahma, Pratik Prabhanjan and Wu, Dapeng and She, Yiyuan},
  month      = oct,
  year       = {2016},
  note       = {Number: 10},
  pages      = {1997--2008}
}

@phdthesis{limbeck_computation_2014,
  type   = {{PhD} {Thesis}},
  title  = {Computation of Approximate Border Bases and Applications},
  school = {Universität Passau},
  author = {Limbeck, Jan},
  year   = {2014}
}

@article{HELDT20091566,
title = {Approximate computation of zero-dimensional polynomial ideals},
journal = {Journal of Symbolic Computation},
volume = {44},
number = {11},
pages = {1566-1591},
year = {2009},
note = {In Memoriam Karin Gatermann},
issn = {0747-7171},
doi = {https://doi.org/10.1016/j.jsc.2008.11.010},
url = {https://www.sciencedirect.com/science/article/pii/S0747717109000935},
author = {Daniel Heldt and Martin Kreuzer and Sebastian Pokutta and Hennie Poulisse},
keywords = {Buchberger–Möller algorithm, Ideal membership, Border basis},
abstract = {The Buchberger–Möller algorithm is a well-known efficient tool for computing the vanishing ideal of a finite set of points. If the coordinates of the points are (imprecise) measured data, the resulting Gröbner basis is numerically unstable. In this paper we introduce a numerically stable Approximate Vanishing Ideal (AVI) Algorithm which computes a set of polynomials that almost vanish at the given points and almost form a border basis. Moreover, we provide a modification of this algorithm which produces a Macaulay basis of an approximate vanishing ideal. We also generalize the Border Basis Algorithm ([Kehrein, A., Kreuzer, M., 2006. Computing border bases. J. Pure Appl. Algebra 205, 279–295]) to the approximate setting and study the approximate membership problem for zero-dimensional polynomial ideals. The algorithms are then applied to actual industrial problems.}
}