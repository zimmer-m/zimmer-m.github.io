<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Publications tagged "Optimization" | Max Zimmer</title> <meta name="author" content="Max Zimmer"> <meta name="description" content="Academic website of Max Zimmer. Deep Learning Research Lead at the IOL Lab of ZIB. "> <meta name="keywords" content="Max Zimmer, mathematics, machine learning, deep learning, optimization, neural network pruning, sparsity, quantization, AI4Science, sustainability, TU Berlin, Zuse Institute Berlin"> <meta property="og:site_name" content="Max Zimmer"> <meta property="og:type" content="website"> <meta property="og:title" content="Max Zimmer | Publications tagged " optimization> <meta property="og:url" content="https://maxzimmer.org/publications/tag/optimization/"> <meta property="og:description" content="Academic website of Max Zimmer. Deep Learning Research Lead at the IOL Lab of ZIB. "> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="Publications tagged " optimization> <meta name="twitter:description" content="Academic website of Max Zimmer. Deep Learning Research Lead at the IOL Lab of ZIB. "> <meta name="twitter:site" content="@maxzimmerberlin"> <meta name="twitter:creator" content="@maxzimmerberlin"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.ico"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://maxzimmer.org/publications/tag/optimization/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> <script defer data-domain="maxzimmer.org" src="https://plausible.iol.zib.de/js/script.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Max Zimmer</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/talks/">talks &amp; activities</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/ai_news/">ai news &amp; links</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publications tagged "optimization"</h1> </header> <article> <div class="publications"> <ol class="bibliography"> <li> <div class="row entry" data-tags="optimization"> <div class="pub-thumb-col" data-tags="optimization"><div class="preview"> <img class="preview rounded" src="/assets/img/publication_preview/frankwolfe_lower_bounds.png" data-zoomable> </div></div> <div id="halbey2026lower" class="pub-content-col"> <div class="title"> <a href="https://arxiv.org/abs/2602.04378" class="no-highlight" rel="external nofollow noopener" target="_blank"> Lower Bounds for Frank-Wolfe on Strongly Convex Sets </a> </div> <div class="author"> J. Halbey, D. Deza, <em>M. Zimmer</em>, <a href="http://christopheroux.de/" rel="external nofollow noopener" target="_blank">C. Roux</a>, B. Stellato, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Sebastian Pokutta' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '0'); ">1 more author</span> </div> <div class="periodical"> <abbr class="badge">Preprint</abbr><span class="venue-name"><em>arXiv preprint arXiv:2602.04378</em></span><span class="year"> 2026</span> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm" role="button">Abs</a> <a class="bibtex btn btn-sm" role="button">Bib</a> <a href="https://arxiv.org/abs/2602.04378" class="btn btn-sm" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>We present a constructive lower bound demonstrating that Frank-Wolfe optimization requires Ω(1/√ε) iterations when both the objective function and constraint set possess smoothness and strong convexity. This result confirms that existing convergence guarantees of O(1/√ε) are optimal. We focus on a representative problem: minimizing a strongly convex quadratic over a Euclidean unit ball with the optimizer positioned at the boundary. We introduce a novel computational method for constructing worst-case trajectories and provide an analytical proof establishing our theoretical bound.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">halbey2026lower</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Lower Bounds for Frank-Wolfe on Strongly Convex Sets}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Halbey, Jannis and Deza, Daniel and Zimmer, Max and Roux, Christophe and Stellato, Bartolomeo and Pokutta, Sebastian}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2602.04378}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2026}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row entry" data-tags="optimization"> <div class="pub-thumb-col" data-tags="optimization"><div class="preview"> <img class="preview rounded" src="/assets/img/publication_preview/bit_rounding.png" data-zoomable> </div></div> <div id="kuzinowicz2025objective" class="pub-content-col"> <div class="title"> <a href="https://arxiv.org/abs/2512.10507" class="no-highlight" rel="external nofollow noopener" target="_blank"> Objective Coefficient Rounding and Almost Symmetries in Binary Programs </a> </div> <div class="author"> D. Kuzinowicz, P. Lichocki, G. Mexi, M. E. Pfetsch, <a href="https://pokutta.com" rel="external nofollow noopener" target="_blank">S. Pokutta</a>, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Max Zimmer' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '0'); ">1 more author</span> </div> <div class="periodical"> <abbr class="badge">Preprint</abbr><span class="venue-name"><em>arXiv preprint arXiv:2512.10507</em></span><span class="year"> 2025</span> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm" role="button">Abs</a> <a class="bibtex btn btn-sm" role="button">Bib</a> <a href="https://arxiv.org/abs/2512.10507" class="btn btn-sm" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/ZIB-IOL/BitRoundingAlmostSymmetries" class="btn btn-sm" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>This article investigates the interplay of rounding objective coefficients in binary programs and almost symmetries. Empirically, reducing the number of significant bits through rounding often leads to instances that are easier to solve. One reason can be that the amount of symmetries increases, which enables solvers to be more effective when they are exploited. This can signify that the original instance contains ’almost symmetries’. Furthermore, solving the rounded problems provides approximations to the original objective values. We empirically investigate these relations on instances of the capacitated facility location problem, the knapsack problem and a diverse collection of additional instances, using the solvers SCIP and CP-SAT. For all investigated problem classes, we show empirically that this yields faster algorithms with guaranteed solution quality. The influence of symmetry depends on the instance type and solver.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">kuzinowicz2025objective</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Objective Coefficient Rounding and Almost Symmetries in Binary Programs}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kuzinowicz, Dominik and Lichocki, Paweł and Mexi, Gioni and Pfetsch, Marc E. and Pokutta, Sebastian and Zimmer, Max}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2512.10507}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row entry" data-tags="efficiency, optimization"> <div class="pub-thumb-col" data-tags="efficiency, optimization"><div class="preview"> <img class="preview rounded" src="/assets/img/publication_preview/frankwolfe_pruning.png" data-zoomable> </div></div> <div id="roux2025dontbegreedyjustrelax" class="pub-content-col"> <div class="title"> <a href="https://arxiv.org/abs/2510.13713" class="no-highlight" rel="external nofollow noopener" target="_blank"> Don’t Be Greedy, Just Relax! Pruning LLMs via Frank-Wolfe </a> </div> <div class="author"> <a href="http://christopheroux.de/" rel="external nofollow noopener" target="_blank">C. Roux</a>, <em>M. Zimmer</em>, A. d’Aspremont, and <a href="https://pokutta.com" rel="external nofollow noopener" target="_blank">S. Pokutta</a> </div> <div class="periodical"> <abbr class="badge">Preprint</abbr><span class="venue-name"><em>arXiv preprint arXiv:2510.13713</em></span><span class="year"> 2025</span> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm" role="button">Abs</a> <a class="bibtex btn btn-sm" role="button">Bib</a> <a href="https://arxiv.org/abs/2510.13713" class="btn btn-sm" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Pruning is a common technique to reduce the compute and storage requirements of Neural Networks. While conventional approaches typically retrain the model to recover pruning-induced performance degradation, state-of-the-art Large Language Model (LLM) pruning methods operate layer-wise, minimizing the per-layer pruning error on a small calibration dataset to avoid full retraining, which is considered computationally prohibitive for LLMs. However, finding the optimal pruning mask is a hard combinatorial problem and solving it to optimality is intractable. Existing methods hence rely on greedy heuristics that ignore the weight interactions in the pruning objective. In this work, we instead consider the convex relaxation of these combinatorial constraints and solve the resulting problem using the Frank-Wolfe (FW) algorithm. Our method drastically reduces the per-layer pruning error, outperforms strong baselines on state-of-the-art GPT architectures, and remains memory-efficient. We provide theoretical justification by showing that, combined with the convergence guarantees of the FW algorithm, we obtain an approximate solution to the original combinatorial problem upon rounding the relaxed solution to integrality.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">roux2025dontbegreedyjustrelax</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Don't Be Greedy, Just Relax! Pruning LLMs via Frank-Wolfe}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Roux, Christophe and Zimmer, Max and d'Aspremont, Alexandre and Pokutta, Sebastian}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2510.13713}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row entry" data-tags="efficiency, optimization"> <div class="pub-thumb-col" data-tags="efficiency, optimization"><div class="preview"> <img class="preview rounded" src="/assets/img/publication_preview/sparsefw_pruneddistance.png" data-zoomable> </div></div> <div id="ZimmerSpiegelPokutta+2025+137+168" class="pub-content-col"> <div class="title"> <a href="https://arxiv.org/abs/2205.11921" class="no-highlight" rel="external nofollow noopener" target="_blank"> Compression-aware Training of Neural Networks using Frank-Wolfe </a> </div> <div class="author"> <em>M. Zimmer</em>, <a href="http://christophspiegel.berlin/" rel="external nofollow noopener" target="_blank">C. Spiegel</a>, and <a href="https://pokutta.com" rel="external nofollow noopener" target="_blank">S. Pokutta</a> </div> <div class="periodical"> <abbr class="badge">Journal</abbr><span class="venue-name"> <em>Mathematical Optimization for Machine Learning</em> </span><span class="year"> 2025</span> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm" role="button">Abs</a> <a class="bibtex btn btn-sm" role="button">Bib</a> <a href="https://arxiv.org/abs/2205.11921" class="btn btn-sm" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/ZIB-IOL/compression-aware-SFW" class="btn btn-sm" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Many existing Neural Network pruning approaches either rely on retraining to compensate for pruning-caused performance degradation or they induce strong biases to converge to a specific sparse solution throughout training. A third paradigm obtains a wide range of compression ratios from a single dense training run while also avoiding retraining. Recent work of Pokutta et al. (2020) and Miao et al. (2022) suggests that the Stochastic Frank-Wolfe (SFW) algorithm is particularly suited for training state-of-the-art models that are robust to compression. We propose leveraging k-support norm ball constraints and demonstrate significant improvements over the results of Miao et al. (2022) in the case of unstructured pruning. We also extend these ideas to the structured pruning domain and propose novel approaches to both ensure robustness to the pruning of convolutional filters as well as to low-rank tensor decompositions of convolutional layers. In the latter case, our approach performs on-par with nuclear-norm regularization baselines while requiring only half of the computational resources. Our findings also indicate that the robustness of SFW-trained models largely depends on the gradient rescaling of the learning rate and we establish a theoretical foundation for that practice.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inbook</span><span class="p">{</span><span class="nl">ZimmerSpiegelPokutta+2025+137+168</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1515/9783111376776-010}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Compression-aware Training of Neural Networks using Frank-Wolfe}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Mathematical Optimization for Machine Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zimmer, Max and Spiegel, Christoph and Pokutta, Sebastian}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Fackeldey, Konstantin and Kannan, Aswin and Pokutta, Sebastian and Sharma, Kartikey and Walter, Daniel and Walther, Andrea and Weiser, Martin}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{De Gruyter}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Berlin, Boston}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{137--168}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{doi:10.1515/9783111376776-010}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9783111376776}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row entry" data-tags="optimization"> <div class="pub-thumb-col" data-tags="optimization"><div class="preview"> <img class="preview rounded" src="/assets/img/publication_preview/nashflow.png" data-zoomable> </div></div> <div id="ziemke2021flows" class="pub-content-col"> <div class="title"> <a href="https://www.sciencedirect.com/science/article/pii/S2352146521000284" class="no-highlight" rel="external nofollow noopener" target="_blank"> Flows over time as continuous limits of packet-based network simulations </a> </div> <div class="author"> T. Ziemke, L. Sering, <a href="https://sites.google.com/view/lvargaskoch" rel="external nofollow noopener" target="_blank">L. V. Koch</a>, <em>M. Zimmer</em>, K. Nagel, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Martin Skutella' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '0'); ">1 more author</span> </div> <div class="periodical"> <abbr class="badge">Journal</abbr><span class="venue-name"><em>Transportation Research Procedia</em></span><span class="year"> 2021</span> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm" role="button">Abs</a> <a class="bibtex btn btn-sm" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/pii/S2352146521000284" class="btn btn-sm" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>This study examines the connection between an agent-based transport simulation and Nash flows over time. While the former is able to represent many details of traffic and model large-scale, real-world traffic situations with a co-evolutionary approach, the latter provides an environment for provable mathematical statements and results on exact user equilibria. The flow dynamics of both models are very similar with the main difference that the simulation is discrete in terms of vehicles and time while the flows over time model considers continuous flows and continuous time. This raises the question whether Nash flows over time are the limit of the convergence process when decreasing the vehicle and time step size in the simulation coherently. The experiments presented in this study indicate this strong connection which provides a justification for the analytical model and a theoretical foundation for the simulation.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ziemke2021flows</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Flows over time as continuous limits of packet-based network simulations}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ziemke, Theresa and Sering, Leon and Koch, Laura Vargas and Zimmer, Max and Nagel, Kai and Skutella, Martin}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Transportation Research Procedia}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{52}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{123--130}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Elsevier}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row entry" data-tags="optimization"> <div class="pub-thumb-col" data-tags="optimization"><div class="preview"> <img class="preview rounded" src="/assets/img/publication_preview/fw.png" data-zoomable> </div></div> <div id="pokutta2020deep" class="pub-content-col"> <div class="title"> <a href="https://arxiv.org/abs/2010.07243" class="no-highlight" rel="external nofollow noopener" target="_blank"> Deep Neural Network training with Frank-Wolfe </a> </div> <div class="author"> <a href="https://pokutta.com" rel="external nofollow noopener" target="_blank">S. Pokutta</a>, <a href="http://christophspiegel.berlin/" rel="external nofollow noopener" target="_blank">C. Spiegel</a>, and <em>M. Zimmer</em> </div> <div class="periodical"> <abbr class="badge">Preprint</abbr><span class="venue-name"><em>arXiv preprint arXiv:2010.07243</em></span><span class="year"> 2020</span> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm" role="button">Abs</a> <a class="bibtex btn btn-sm" role="button">Bib</a> <a href="https://arxiv.org/abs/2010.07243" class="btn btn-sm" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://www.pokutta.com/blog/research/2020/11/11/NNFW.html" class="btn btn-sm" role="button" rel="external nofollow noopener" target="_blank">Blog</a> <a href="https://github.com/ZIB-IOL/StochasticFrankWolfe" class="btn btn-sm" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>This paper studies the empirical efficacy and benefits of using projection-free first-order methods in the form of Conditional Gradients, a.k.a. Frank-Wolfe methods, for training Neural Networks with constrained parameters. We draw comparisons both to current state-of-the-art stochastic Gradient Descent methods as well as across different variants of stochastic Conditional Gradients. In particular, we show the general feasibility of training Neural Networks whose parameters are constrained by a convex feasible region using Frank-Wolfe algorithms and compare different stochastic variants. We then show that, by choosing an appropriate region, one can achieve performance exceeding that of unconstrained stochastic Gradient Descent and matching state-of-the-art results relying on L^2-regularization. Lastly, we also demonstrate that, besides impacting performance, the particular choice of constraints can have a drastic impact on the learned representations.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">pokutta2020deep</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Deep Neural Network training with Frank-Wolfe}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pokutta, Sebastian and Spiegel, Christoph and Zimmer, Max}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2010.07243}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright <script>document.write((new Date).getFullYear());</script> Max Zimmer · <a href="https://maxzimmer.org/legal-notice">Legal Notice</a> · <a href="https://maxzimmer.org/privacy-policy">Privacy Policy</a> </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams",inlineMath:[["$","$"]]}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/publications.js"></script> </body> </html>